{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C1UFxvFAuCmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685c6ba4-aaa7-4a81-fd24-49753350835f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.16.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from kagglehub import dataset_download\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "piKnMg4yyTwf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"agungpambudi/mnist-multiple-dataset-comprehensive-analysis\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdD6x3RzIeX",
        "outputId": "16ec2445-ebe1-4765-c44c-4ba0b8db63a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/mnist-multiple-dataset-comprehensive-analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/kaggle/input/mnist-multiple-dataset-comprehensive-analysis\"\n",
        "base_path = os.path.join(dataset_path, \"PolyMNIST\", \"MMNIST\")\n",
        "\n",
        "data = []\n",
        "\n",
        "for split in [\"train\", \"test\"]:\n",
        "    split_path = os.path.join(base_path, split)\n",
        "    if not os.path.exists(split_path):\n",
        "        continue\n",
        "    for modality in os.listdir(split_path):\n",
        "        modality_path = os.path.join(split_path, modality)\n",
        "        if not os.path.isdir(modality_path):\n",
        "            continue\n",
        "        for file in os.listdir(modality_path):\n",
        "            if file.endswith(\".png\"):\n",
        "                try:\n",
        "                    label = int(file.split(\".\")[1])  # Ej: 1234.5.png → 5\n",
        "                    full_path = os.path.join(modality_path, file)\n",
        "                    data.append({\n",
        "                        \"file_path\": full_path,\n",
        "                        \"label\": label,\n",
        "                        \"modality\": modality,\n",
        "                        \"split\": split\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error con archivo: {file} → {e}\")\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"DataFrame generado con\", len(df), \"registros.\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "ZbpmXrD1x7aW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a289a9-6490-49aa-f444-6aba2f6573fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame generado con 350000 registros.\n",
            "                                           file_path  label modality  split\n",
            "0  /kaggle/input/mnist-multiple-dataset-comprehen...      9       m4  train\n",
            "1  /kaggle/input/mnist-multiple-dataset-comprehen...      0       m4  train\n",
            "2  /kaggle/input/mnist-multiple-dataset-comprehen...      0       m4  train\n",
            "3  /kaggle/input/mnist-multiple-dataset-comprehen...      9       m4  train\n",
            "4  /kaggle/input/mnist-multiple-dataset-comprehen...      9       m4  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ElasticTransform:\n",
        "    def __init__(self, alpha=36, sigma=6):\n",
        "        self.alpha = alpha\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, img: Image.Image) -> Image.Image:\n",
        "        arr = np.array(img)\n",
        "        shape = arr.shape[:2]\n",
        "        # campos de desplazamiento\n",
        "        dx = (np.random.rand(*shape)*2 - 1)\n",
        "        dy = (np.random.rand(*shape)*2 - 1)\n",
        "        dx = gaussian_filter(dx, self.sigma) * self.alpha\n",
        "        dy = gaussian_filter(dy, self.sigma) * self.alpha\n",
        "        # mallas\n",
        "        x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
        "        map_x = (x + dx).astype(np.float32)\n",
        "        map_y = (y + dy).astype(np.float32)\n",
        "        # aplica remap canal por canal\n",
        "        warped = np.stack([\n",
        "            cv2.remap(arr[...,c], map_x, map_y,\n",
        "                      interpolation=cv2.INTER_LINEAR,\n",
        "                      borderMode=cv2.BORDER_REFLECT_101)\n",
        "            for c in range(3)\n",
        "        ], axis=2)\n",
        "        return Image.fromarray(warped)\n",
        "\n",
        "# Transforms para train / test\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((28,28)),\n",
        "    ElasticTransform(alpha=36, sigma=6),\n",
        "    transforms.ToTensor(),                                # [0,1]\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))     # [-1,1]\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((28,28)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "wL1-DRsjxZRF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RGBMNISTDataset(Dataset):\n",
        "    def __init__(self, df, split, transform):\n",
        "        self.sub = df[df['split']==split].reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sub)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.sub.loc[i]\n",
        "        img = Image.open(row.file_path).convert(\"RGB\")\n",
        "        return self.transform(img), row.label\n",
        "\n",
        "train_ds = RGBMNISTDataset(df, 'train', transform_train)\n",
        "test_ds  = RGBMNISTDataset(df, 'test',  transform_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=8)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=8)"
      ],
      "metadata": {
        "id": "QJ_0aSxJxm0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f567024b-b6ad-44fc-db48-1e05d21bbdb3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNet(nn.Module):\n",
        "    def __init__(self, input_dim=3*28*28, hidden=800, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,3,28,28]\n",
        "        x = x.view(x.size(0), -1)    # aplanar → [B,3*28*28]\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iC0bZdRJxqJ2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TwoLayerNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_acc\": []\n",
        "}\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            preds = model(x).argmax(dim=1)\n",
        "            correct += (preds==y).sum().item()\n",
        "            total   += y.size(0)\n",
        "    return 100*correct/total\n",
        "\n",
        "def evaluate_loss(loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            out  = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            total_loss += loss.item() * y.size(0)\n",
        "            total      += y.size(0)\n",
        "    return total_loss / total\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out  = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "\n",
        "    train_loss = total_loss / len(train_loader.dataset)\n",
        "    val_loss   = evaluate_loss(test_loader)\n",
        "    train_acc  = evaluate(train_loader)\n",
        "    val_acc    = evaluate(test_loader)\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{epochs} | \"\n",
        "          f\"Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "epochs_list = list(range(1, epochs+1))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_list, history[\"train_loss\"], marker='o', label=\"Train Loss\")\n",
        "plt.plot(epochs_list, history[\"val_loss\"],   marker='o', label=\"Val Loss\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"Loss\"); plt.legend(); plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_list, history[\"train_acc\"], marker='o', label=\"Train Acc\")\n",
        "plt.plot(epochs_list, history[\"val_acc\"],   marker='o', label=\"Val Acc\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"Accuracy (%)\"); plt.legend(); plt.show()"
      ],
      "metadata": {
        "id": "_PbPBz8pxsPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a0fc9c-9736-4a07-ef70-12bc74202fbb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 0.9284 | Train Acc: 77.19% | Test Acc: 85.29%\n",
            "Epoch 2/5 | Loss: 0.7175 | Train Acc: 80.32% | Test Acc: 87.60%\n",
            "Epoch 3/5 | Loss: 0.6560 | Train Acc: 81.60% | Test Acc: 88.28%\n",
            "Epoch 4/5 | Loss: 0.6225 | Train Acc: 82.70% | Test Acc: 89.22%\n",
            "Epoch 5/5 | Loss: 0.6000 | Train Acc: 81.12% | Test Acc: 87.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_random_image(model, dataset, class_names=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    idx = random.randint(0, len(dataset) - 1)\n",
        "    image, label = dataset[idx]\n",
        "    image_input = image.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(image_input)\n",
        "        pred = torch.argmax(out, 1).item()\n",
        "\n",
        "    # des-normaliza y pasa a numpy para plt\n",
        "    img_np = image.permute(1,2,0).cpu().numpy()\n",
        "    img_np = (img_np * 0.5 + 0.5).clip(0,1)\n",
        "\n",
        "    plt.imshow(img_np)\n",
        "    plt.title(f\"Real: {label} | Predicho: {pred}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HMzR-Q6JMQ4H"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_random_image(model, test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "336OvN88MUTt",
        "outputId": "00e9e8b4-6ec1-4610-8867-c3355a8ae2ce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}